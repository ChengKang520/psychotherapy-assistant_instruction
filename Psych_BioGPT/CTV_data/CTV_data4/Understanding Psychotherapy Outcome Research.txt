00:00:00
TRANSCRIPT OF VIDEO FILE: 

00:00:00
_____________________________________________________________________ 

00:00:00
BEGIN TRANSCRIPT: 

00:00:00
MICROTRAINING 

00:00:00
AN IMPRINT OF ALEXANDER STREET 

00:00:05
GREAT TEACHERS 

00:00:05
GREAT COURSES 

00:00:10
Understanding Psychotherapy Outcome Research 

00:00:10
Presented By 

00:00:10
EVELYN BEHAR, Ph.D. 

00:00:10
UNIVERSITY OF ILLINOIS 

00:00:15
EVELYN BEHAR, Ph.D. 

00:00:15
ASSOCIATE PROFESSOR, UNIVERSITY OF ILLINOIS 

00:00:15
EVELYN BEHAR Hi, my name is Evelyn Behar. I am an associate professor at the University of Illinois in Chi… at Chicago in the Department of Psychology. And I'm here today to talk about, umm… understanding Psychotherapy Outcome Research. And I have been doing psychotherapy outcome research for about 17 years. Umm… I am a Psychotherapy Outcome Researcher and I'm also an anxiety researcher. And in my own research program, I sort of, try to combine these two things, in order to learn what the most effective, umm… treatment approaches are for the treatment of anxiety and fear disorders. So, umm… with that, we will go ahead and get started. And today I will be talking about, umm… understanding Psychotherapy Outcome Research. So anytime you do Psychotherapy Outcome Research, there are really, sort of, two steps, umm… to designing these studies. The first step is to, umm… pick a design. So, before you do anything, you want to decide, you know, "Am I gonna have a dismantling design? Am I going to use a… an additive design? A catalytic design? A parametric design?" And there's another video, there's another lecture, umm… that really focuses on the differences between those designs and how to best choose between them depending on your research question. And in this lecture, we are gonna be talking a little bit more about some other elements of the design that are crucial to take in to consideration, umm… in order to umm… increase the strength of causal conclusions that you can draw from these types of studies. So first let's talk a little bit about some general methodological considerations. And I think some of these you'll recognize from typical every day, umm… experiments that, you know, when you are designing an experiment, there are lots of things that everybody knows that you have to take into consideration, that's no different from Psychotherapy Outcome Research. Psychotherapy Outcome studies are experiments. There is really no difference, it's just that it's a special of experiment, so there are additional concerns that you have to take into consideration. Okay, so the first thing as we know, I mean, anybody who has every taken a Research Methods class knows that the number one thing that distinguishes between a true experiment and not a true experiment is random assignment, right. So, you've got to randomly assign your participants to different conditions of the study in a way that each participant has an equal chance of ending up in those different conditions. And, umm… what does this do? So, we know that random assignment, sort of, takes care of individual differences, that's the primary thing that it does. So that if you have two conditions in your study, you are going to randomly assign people either to get this treatment or this treatment, umm… you want to make sure that certain individual differences are equivalent at baseline across those two conditions, right. You don't want the people with the most severe depression ending up in this group, but not in this group. You want to make sure that at baseline, those two groups are equivalent on levels of depression. Or for example, you want to make sure that not everybody in group one, ki… is divorced and, where as everybody in group two is in a stable marriage because if you find differences at post-test, maybe it's not due to your treatment, maybe it's due to the fact that there's something about individuals who are divorced, that makes them different on this outcome variable relative to individuals who are in stable marriages. So, we know that random assignment is crucial and we understand the reasons why. Now in Psychotherapy Outcome Research, it's important to randomly assign your participants to treatment within waves. So, let me explain what that means. For a study with three conditions, for example, right. So, let's say that you have a dismantling study and you are randomly assigning your participants to receive either cognitive behavioral therapy, the full package or cognitive therapy alone or behavior therapy alone. You want to randomly assign the first three people who come into the study to those three conditions, okay. So, you are randomly assigning, but you're randomly assigning with a caveat and that's that, it's not true random assignment, because you are not saying, "Listen." The second person who come… if the first person who comes in, goes into group one, the second person who comes in does not have any chance of ending up in group one. That person is going to go either groups two, group two or group three. The third person to come in is gonna go into the one that the second person didn't. So why is that we do this? Umm… Because really, we, in many ways, we are compromising on the number one most important thing in an experiment, but we are doing it for a good reason. So imagine that you print out your random assignment, umm… assignments, right. And listen, the computer generated these numbers eq… you know, at random. And all of a sudden, the first 10 people are in group one. They are in that first condition and you are starting your study. Now those therapists who are treating these individuals are going to get better overtime, right. Aren't they? Now as they become more expert in the therapy, as they become more comfortable with how to do this treatment, they're gonna get better. So now you've got 10 people who got the therapist at their worst. And then, you've got the rest of the people who are getting their… their therapist at the best. Maybe, the people in group two are getting the therapist once the therapists are already better trained. You are gonna end up with basically a cohort effect, right. You're… It's not… It's not really a fair test. And, you know, there are other things, like something might happen in the world, maybe there is a terrorist attack, umm… in the city where the treatment is being run. And all of a sudden, you know, you've got way more people having been run in treatment in the first condition than in the second condition. And then the terrorist attack hits and so now you've got more people coming in for the second condition and if they show differential outcome from the first condition, maybe it's not due to the treatment, maybe it's due to this thing that happened in society and in the city where you live. So, umm… So random assignment within waves really controls for various factors that might, umm… impact outcome that are really unrelated to the studies, so things like seasons, right. What if you are treating Seasonal Affective Disorder? And now, all the people who ran in the summer in group one and all the people you are running in the winter in group two, it's better to randomly assign them within waves. So that you've got everybody coming in, getting one of those three conditions, then people coming in getting one of those three conditions. So you make you sure that over the seasons, over the passage of time, you have equivalent numbers of people being run in each condition. Umm… Maybe you change therapist halfway through, maybe one of your therapist quit… quits the study, and you have to hire somebody else. Well, now you don't want there to be a therapist effect, right. You want to make sure that those different conditions are having equivalent access to the different therapists, umm… etcetera, etcetera. We can probably think of lots of different ways in which, umm… this… this would be an… it would be important to randomly assign participants within waves. So yes, we are compromising a little bit on the integrity of random assignment, but I think the pros outweigh the cons. And remember, you are still randomly assigning, it's just with a caveat. Okay, the second thing to take into consideration, umm… is something called session parameters. So we know that, again, we want to make sure that all different elements of the different conditions are equivalent except the one thing that we are randomly assigning, right, that one independent variable manipulation. So, let's say that you have two conditions in your study, two different treatments. The first one requires two hours of therapy per week, and the second one really only requires one hour of therapy per week. Now when you find… if you find a difference in outcome between condition one, and condition two, it maybe that that difference is due the actual treatments, it very well may be. But you can't rule out the possibility that it's because of this dose of therapy, right. That these guys got twice as much therapy as these guys did. It may not be the type of therapy, it maybe the amount of therapy that's causing that change. And so, what you want to do here is you want to sure that you are holding constant, the number of sessions and the number of minutes per session. So, let's look at an example. If you have, umm… here, dismantling design and you are randomly assigning your participants to one of three groups where the first group has cognitive therapy plus behavior therapy, second group has cognitive therapy alone, third group has behavior therapy alone. Then let's say that cognitive therapy and behavior therapy are each going to take 30 minutes for those components, right. And here, of course, you want to give these guys 30 minutes of cognitive therapy, in order to match the amount of cognitive therapy that's being delivered here. So you don't want to give these guys a double dose. But now all of a sudden, you've got group one getting a total of 60 minutes and group two getting a total of 30 minutes. So what you want to do, is you want to basically use a filler, where, for 30 minutes, in order to control for the additional 30 minutes here, you are going to, umm… deliver supportive listening. And this is, sort of, a Rogerian approach to therapy, like coming from Carl Rogers, where you don't actually do any specific intervention, you really just provide some of the basic foundations of therapy for the client. And, you… you know, you say things like, umm… that sounds like it was a really difficult experience, can you tell me a little bit more about that? What happened then? How did you deal with it? But you don't actually intervene, so you don't change, you don't try to change them in anyway, you only deliver those common factors, those nonspecific elements of therapy. And in group three, you do the exact same thing. And this way you are holding constant the dose of each individual component of therapy, it's always 30 minutes. And you are holding constant the number of total minutes of therapy in each, umm… session. And also, you want to make sure to, umm… take into consideration the number of sessions, right. So you don't want these guys getting 20 sessions and groups two and three getting 10 sessions. You want to make sure that everything is held constant, so that if and when you find differences, it wasn't due to different session parameters, it was due to the actual interventions. So, it really helps you to increase the confidence of your causal conclusions. Okay, the third thing to take into consideration is this idea of therapy manuals. So, anytime you do a therapy, you know, if you just go to a regular therapist in the community, very often they are not using a therapy manual, they are just doing therapy, right. They don't tell you, "Okay, this therapy is going to consist of 16 sessions, one hour each, where we are going to be doing this and this and this." It's not quite a structured as it can be in some psychotherapy outcome studies. But in a psychotherapy outcome study, you need to really make sure that your independent variable is being delivered the way that you intended it to be delivered where the independent variable is the treatment, right. You don't just want anything and everything being done. You want to make sure that it's being done according to a specific definition. So, a therapy manual really allows you to develop an operational definition of your independent variable, a way of defining this treatment. So, what you do in the therapy manual, you provide detailed procedures to be followed in each condition of the study. Umm… Often they prese… the manuals present session by session outlines, so that the therapists know, in session one, I've got to achieve these goals, this is how I achieve them. In session two, I've got to achieve these goals, this is how I achieve them, and so on and so on. And they even outline specific techniques, right. So they'll say, "Okay, to achieve this goal, you are going to do, umm… exposure and cognitive restructuring and this and that and the other. Umm… It also allows for standardized implementation of the therapy across clients within each condition, so in, umm… if you are delivering cognitive therapy by itself, you want to make sure that cognitive therapy is looking the same for all of the participants in that condition. You don't want it to look drastically different across people, right. So for example, if one therapist, maybe just prefers doing, umm… uh… automatic thought tracking on thought logs, and another one really prefers a different approach. Well, you really want to standardize this because this is your experiment. You've got to keep things constant. So the manual allows you to say to the therapist, "Look, this is how you are going to do this." Or "These are the many ways in which you can do this." Now pick the ones that are, that gonna, you know, that you feel will be the most amenable to this particular client. It also importantly allows for replication by other investigators, right. So if you publish this study and now somebody at University of Iowa wants to replicate your study, you want them to have the ability to do it in the way that you did it and so you can just send them your therapy manual or maybe your therapy manual is published. Umm… And it also allows therapists in private practice to say, "Hey, this is clearly an effective therapy. I want to do that in my private practice." They can just ask you for the manual or order it off of Amazon.com. Umm… There's actually, there's a whole collection of treatment manuals, it's the Treatments That Work series, it's edited by David Barlow at Boston University. It's basically every disorder in the DSM. There is a therapy manual for… umm… that corresponds to a treatment outcome study. It's a really great resource that allows practicing clinicians to essentially speak the same language, as the original investigators, and be able to deliver the treatment in the same way. So, the criticism of the therapy manuals is that it's always the same. People say, "Well, it's so robotic. It's a formula. You know, my cl… my clients don't fit into this formula. My clients are unique, they are their own people, they don't just fit this little formula that you have here in your manual." And you know, I would say that the… the goal of a therapy manual is not to deliver treatment like a robot, that's really not what it's about. It's a way of defining the independent variable. So you can say it to all of the therapists in the study, "Look, this is what I need you to do. These are the possible ways of doing it. Now go and deliver it in a way that adapts well to your specific person with all of his or her specific stuff, and all of their idiosyncratic ways, and all of their individual little quirks, and, you know, individual thoughts, and maladaptive behaviors, and this and that. So go and adapt it, but here is the basic framework that I need you to work from." And I think that is a good use of a therapy manual whereas the people who really use it as a cook book, like for baking, that's really not a good use. I always think of it as the difference between baking and cooking, right. If you're gonna bake, you better measure everything and you better follow that recipe exactly otherwise the cake is gonna fall or the soufflé is just gonna be flat. But if you are cooking, you know, an Indian dinner or a Mediterranean dinner or whatever, you don't have to follow that recipe exactly, exactly, exactly, but you know what the general ingredients are. You know what the general approach is. You know that you got to cook the chicken for "x" amount of time. So it really, it gives you a framework just like a therapy manual does, but it also allows you to, kind of, do your own thing, right. It allows you to adapt it to what your family would prefer to eat for dinner or, you know, your son doesn't like fennels, you're gonna leave out the fennels seeds or whatever. Okay. Umm… All right. The next thing is adherence checks, and these are really, really important. So this is basically a manipulation check. In any experiment you want to have some sort of manipulation check, right. You want to make sure my manipulation actually took. And so generally people have umm… investigators have manipulation checks in their experiments. Psychotherapy Outcome Research is no different, but here you really it… it takes place, sort of, behind the scenes. So, adherence is the degree to which therapists adhere to the treatment protocol or the treatment manual, right. So you really want to make sure that these therapists are doing what they are supposed to do and following the treatment the way that you intend for it to be, umm… to be administered. So you have to ensure, as the investigator, you have to ensure that the therapists don't break the protocol. And most importantly, you have to make sure that no cross contamination happens. So here is an example. If you have, umm… some… If you're randomly assigning participants to either get, umm… cognitive therapy versus cognitive therapy plus behavior therapy, right. In that cognitive therapy alone condition, that first condition, you cannot have any behavior therapy. You have to make absolutely sure. Otherwise you're contaminating the two, right. And then the… the umm… the comparison is an unfair comparison. So in that first condition, you've got to listen, you have to employ somebody to listen to every single therapy tape. And with a checklist of all allowed utterances and not allowed utterances. And anything that suggests to the client, you have to behave in this new way, is not allowed and that's a break in protocol, to break an adherence. So, umm… this obviously can be very orneriest. So if you have 100 clients enrolled in your treatment outcome study with 20 sessions each. You know, that's a lot of sessions to listen to and a lot of checklist to go down and make sure and then re-listen to make sure that you didn't do it wrong. And then you need a second coder to make sure that there's a liability with the first coder. It's too much and most people don't have those resources either in money or in time. So a lot of people just select 20% to 25% of session recordings and they go ahead and they do the adherence checks on those. And again as I said, you categorize each one of the therapist utterances against a checklist of allowed techniques and not allowed techniques or allowed utterances and not allowed utterances. And you want to allow utterances or techniques that are related to that, umm… to that specific treatment conditions protocol. And you definitely want to not allow anything that, umm… it belongs to a different condition, that's for sure. And, umm… not allow anything that is really specifically and uniquely related to some other treatment approach, right. So if you start exploring, umm… you know, issues of defensiveness and you are trying to do behavior therapy. Well, now you're, all of a sudden, you are taking from a psychodynamic tradition and that might really be problematic for an investigation of behavior therapy as it is supposed to be delivered in this pure way. Umm… And importantly you want to pick some, sort of, a standard by which your study has to abide. So you want to pick a cut-off for how many protocol breaks you're going to allow before you toss that participants data. And, umm… you know, there are some studies where you end up tossing 20 participants data. And if you did 20 treatment sessions on these 20 people, then you have to exclude them because of protocol breaks, it hurts, it, like, hurts. It hurts in your soul to throw out data from those 20 people. So it's important to, umm… communicate to the therapist how crucial this is. And if there are more than "x" number of breaks, you're gonna have to get rid of that clients data, even though you're, obviously, you're gonna continue treating the client. So the more stringent the criteria, the more likely you are independent variable is to be the only thing that varies between conditions. And then the stronger the internal validity of you study, so the stronger your cause and effect conclusions. So, umm… I know of at least one study where only two breaks in protocol were allowed, across 16 sessions, that's a very stringing criterion and it required the therapist to be very, very, very careful. And I… I think only a couple of, umm… clients data were tossed, which is a big relief because that's a very hard, umm… it's a very hard standard to me. Okay. Umm… The fifth issue is Therapist Competence. Umm… So, of course, we all know what competence is, right. It's the extent to which the therapist implements the intervention skillfully and expertly. Now interestingly, you know, in the world of psychology and in the world of therapy, we don't have a good way of measuring how expertly, uh… treatment is delivered or how competently or how skillfully, there is no objective measure of how well someone actually administer the therapy. So what a lot of people do is they will employ, umm… sort of, like, you know, a top name in that type of therapy to listen to the tapes. And, you know, this goes into the budget for the grant where you're gonna pay John Gottman to listen to your, uh… behavior therapy for marital distress tapes and make sure that, yes, in fact, the therapists were, uh… administering this treatment in a way that he perceives subjectively as being expert and competent and skillful. So that kind of, boosts, umm… some believability in the, uh… in the… in the quality of the treatment that was provided. And of course, you want to see equivalent levels of therapist competence across your different conditions, right. So if you send them to John Gottman, for rating, he's not gonna know which condition people are in. He's not… He should not know what the purpose of the study is. He's just listening and saying, yup, that was delivered expertly, that technique was done very well, that technique was done very well. And then you collect all of John Gottman's rating and you say, all right, I'm really hoping that my three conditions are equivalent. If they are not, then if you find differences across conditions in the end, maybe it's not the treatment, maybe it's the level of expertness or skillfulness with which the treatment was delivered, which is really just unique to your study and doesn't generalize to greater knowledge out there, so this is really important. Okay. The sixth thing is, umm… Credibility and Expectancy. So we know that in the world of medication, right, there is something called the placebo effect. And we know that if someone says to us, "Oh, you have allergies?" Here, take this pill, this is shown to be the most effective pill for allergies and you take it, saying your allergies are gonna be less bad. You're gonna be ameliorated. And it could just be a sugar pill, but we know that human beings when they expect themselves to feel better, they feel better. And so this translates to psychotherapy as well, right. If I am terribly, terribly depressed and I go and I pay $400 a session to see the top depression therapist in the world, I'm expecting to get better and guess what? I'm probably gonna get better whether that therapy was delivered well or not, whether that therapy is effective or not. So we know… we all know the importance of patient expectancy, hope, faith and credibility, all of these elements really do effect how people feel. So, umm… we have to make sure that all of the conditions of our study are equivalent on credibility and expectancy ratings. If they differ, then if we find conditi… if we find differences between conditions at the end, it could be because of the therapy or it could be because of the psychological placebo effect, right, this expectancy to get better. And there are… luckily there are something called the credibility and expectancy questionnaires published a long time ago, I think, in the '70s by Tom Borkovec. And it's, sort of, the most commonly used, uh… measure of credibility and expectancy. You just give to every single person, after the first session, when you first explain the rationale for therapy. You give it to them, they fill it out and then you hope and pray that your conditions are equivalent on credibility and expectancy of getting better. If they are not, then you have a rival hypothesis. There's nothing you can do about it. You can't go back and fix it, but you have a rival hypothesis for any between group's differences that emerge in the end. Okay, the seventh thing is, umm… Dropout and Attrition. So these are actually two different terms. Dropout refers to the loss of participants during the treatment period. So in a 16 session protocol, after the 9th session somebody drops out, says, you know what? I don't like your therapy, or my life has gotten too complicated, or my family is moving, and sorry, see you, uh, good luck with your study and you lost the person. Umm… Attrition is the loss of participants during the follow-up period. So they go through your 16 weeks. But now you want to follow them for two years. And a year in to that follow-up period they say, uh! I don't want to… I don't want to show up at the university anymore and fill out all these questionnaires and do all these interviews, I'm done. And so now there is attrition. So why do participants leave studies? Well, we all know there are tons of reasons. Number one, you know, there could have been dissatisfaction with the therapy. Maybe they don't like the therapy that you're giving them or they don't like the therapist that they were assigned. Maybe they are not getting better. And they are frustrated and so they are gonna somewhere else and look for a therapist elsewhere. Maybe they're uncomfortable with emotions and you're doing emotion focused therapy. And you are doing the very thing that they hate the most in the world and that by the way, they need the most in the world, but they hate it. Umm… Or they just, you know, they are busy and they just don't have time to be in a treatment outcome study that requires them to do homework in-between sessions, fill out a bunch of questionnaires, etcetera, etcetera. So we… we know that some dropout and attrition is always going to occur in psychotherapy outcome research. It's almost impossible to completely, umm… sidestep it. But how can you minimize it? So number one, you know, you can sit and explain to the clients, at the beginning, how important this study is. You can say to them, you are doing a huge service to the world. You are helping us discover better ways to treat people who are chronically and severely depressed. We deeply appreciate your contribution to our study. Umm… And I think, like, when there's a sense of belonging and a sense of service, people are more likely to stay. You can pay them. Umm… You can remind them that they are getting a therapy that is worth thousands of dollars for free. And you can make sure that the therapist, the study therapist establish a very strong therapeutic relationship with their clients, so that, you know, when there's a good therapeutic relationship, dropout is lower. And so, umm… you know, you've got an… like no… don't be robotic in your delivery of the treatment. Like really be warm and empathic and build a good alliance, etcetera. So all of those things will help decrease the rate of dropout and attrition. But we still know that it's gonna happen to some degree. And the thing to keep in mind is that there's a difference between homogenous attrition and heterogeneous attrition. Homogenous attrition is when across conditions, you have the same rate of dropout. Maybe you have two people who dropped on, on condition one, two people in condition two, two people on condition three. That's bad, but you can sleep at night. You can't sleep at night when, umm… when you have heterogeneous attrition. When you have 10 people who dropped out in the first condition and only one person in the other two conditions. Now you say to yourself, well, there're two issues, right. So now differences at post-therapy and follow-up. Was it due to the treatment or was it due to the fact that maybe they are… like all the really severe people left this condition or there's something now about the participants and not the treatments? It's the participants who are different. So that, it really is the… the biggest worry, right. The second thing is, if there is a treatment where 50% of clients are dropping out. Do you really want to put that out there? Like, maybe it's just not… It's not a treatment that people are really going to want as consumers. And that needs to be taken into consideration. So, lots of things to think about, umm… in the world of dropout and attrition. Okay. So those were, umm… seven, uh… sort of, general methodological considerations in the world of, umm… treatment outcome research. And now let's look at some specific issues that are really related to the client, to the participant in the study. Okay. So the first thing that you have to take into consideration is, where you're getting your clients from, right. So you're ready to start your big study. You're looking to enroll 150 people. You're gonna randomly assign 50 people to condition one, 50 people to condition two, 50 people to condition three, ready to go. But where are you gonna get these people from? Right. So there are some sources of umm… referrals that are common. Mental health agencies in the area can be a great source of referrals. Private practice psychologists, you know, maybe there are some private practitioners who have a long waitlist and they are more than happy to get rid of some people on their waitlist, so that they don't feel guilty and they can sleep at night. Media advertisements, sometimes you hear, like, on the radio, you know, different, umm… studies being, uh… being advertised. Or you'll be riding the subway and you see an advertisement for, you know, "Do you suffer from ADHD? We have a treatment for you," and so people can call. Or postings, now this is a new thing, postings on social media sites, you know, on Twitter, on Facebook, etcetera, etcetera. Umm… And the important thing here is not, I mean, it's great to have people from all different sources, that's fine. But you want to make sure that across the conditions of your study, you have an equivalent representation of those sources, right. So what happens if everybody from condition one came from a mental health agency in the area, but nobody in condition two or three came from the mental health agency? Or maybe there is something about people from mental health agencies that is somehow fundamentally different. And now if you find that condition one was not as good as conditions two and three, you've got a rival hypothesis. Maybe it was the therapy that was different, caused different changes or maybe it was the partic… the source of participants that was really, umm… the culprit. It's a little bit difficult to Apriori(ph), sort of, decide, okay, I'm gonna put "x" number of people from this referral source here, and here, and here, because they come from where they come from, but it's something that you want to check at the end. You want to just make sure, okay, I didn't end up with… in this condition, everybody from this referral source and no other referral sources. Okay. Uh… the second thing in the world of client and participant characteristics is, umm… selection criteria. Umm… Sorry, no. The second thing in, kind of, participant characteristics, umm… is basically just descriptive information on who your clients are. So you want to just be careful to collect information on everybody's age, ethnicity, marital status, socioeconomic status, gender, medication status, education level, sexual orientation, basically anything that would matter to a reader of this study, to know who were these people, right. So a long time ago, umm… people would run, researchers would run these psychotherapy outcome studies. And it was like 94% of the participants were Caucasian, heterosexual, married, high level of education and, you know, only met criteria for one disorder. And then the National Institute of Mental Health came along and said guys, this is totally unrealistic because what if these treatments are only effective for these specific types of individuals, but not effective for people with different sexual orientations, or different rational ethnic backgrounds, or different socioeconomic status backgrounds, or people with high degrees of comorbidity. And so there was really a push to include a much more diverse sample into the overall sample. And so you just want to keep track of this, so that you can make some judgments about how generalizable your findings are to the greater population. And ideally, you also want to try to, umm… emulate the rate of all of these different, umm… categories in the general population. So if you know, that in the city where you live, 50% of participants are Caucasian, then you want to be careful to not have 90% of the participants in your study be Caucasian because now it doesn't represent the greater city where you live, the, umm… the… the area where you live. Okay. And most importantly, you want to make sure that you don't end up with all the wealthy people in condition one and no wealthy people in conditions two and three, right. So you want to just make sure that there is an equivalent representation of all of these demographic variables across the three conditions because again any differences that exist between your three conditions other than the independent variable will represent a rival hypothesis for why you found what you found, why you found between groups differences in the end. Okay. Umm… There is also, umm… this issue of selection criteria. So you want to just be very careful and decide in advance what your inclusion criteria are going to be and what your exclusion criteria are going to be? So are you looking for a particular diagnosis or a clinical problem? Maybe you're looking only for people with insomnia. Or maybe you are looking only for people who are high on rumination and you want to do a rumination intervention. Umm… So you just want to be very clear about who it is that you are looking for and then have a way of assessing it, umm… accurately and validly. So are you excluding certain comorbid conditions, right. So you want to ensure that the rates and the type of comorbid conditions are equivalent across conditions of the study. And you want to decide in advance, am I… If I'm treating depression, am I going to exclude individuals who meet diagnostic criteria for psychosis? You know, because that's, it's a separate problem. Maybe I just don't want to include this particular population in my particular study, leave it to a different study to figure out how to best treat the combination of depression in psychosis. Umm… And keep in mind, that with every exclusion criterion that you have, you got to trade off here. You have a more homogenous sample, so you have a cleaner sample, but you are sacrificing external validity, right. You're sacrificing the generalizability of your findings, because now if you say, okay, no psychotic individuals in my study. Or here's a better example, no suicidal in individuals in my, umm… in my clinical trial where I'm treating OCD, right. Well, there are people with OCD who are suicidal. It exists in the world and so if you're going to exclude suicidal individuals, that's fine. But now you have to ask the question. Well, are my findings generalizable to individuals with OCD, who by the way, are really thinking of harming themselves or killing themselves and that be… it's a tradeoff. Umm… Okay. And you have to also remember that the final sample is going to consist of clients who were willing to be in a research study. So, it's possible that your particular sample is more severe or maybe less severe. Umm… Maybe they have higher motivation to change than the general population. Maybe they have greater expectancy and credibility in this treatment. Otherwise you would have lost them early on, umm… etcetera. There are so many different ways in which a research sample is going to potentially differ from an everyday sample. And those are just things that you really have to keep in mind when you start to think about issues of external validity and generalizability. Okay. The next thing to keep in mind, in terms of the clients or the participants, is severity and duration of the problem. So you need to assess, not only the severity of the problem, but how long the problem has been a problem for each individual. And you can do this in lots of different ways. You can do it with self-report measures. You can use severity ratings on interviews. Like for example, the anxiety disorders, interview schedule has a way of rating from zero to eight, the severity of each individual anxiety diagnosis and depression. And people are trained to reliability before they are certified and how to administer this interview. So, it's important because again these are things that can impact outcome, right. If I am an eight, on a zero to eight scale, in terms of the severity of my panic disorder, then maybe it's unrealistic to expect me to go to a one, you know, but I might get to a four and that's huge. And so across conditions, you want to make sure that the average severity is equivalent, right. You don't want the most severe people ending up in one condition, but not the other two conditions or the other three conditions or whatever. And duration of the problem, you don't want everybody in one condition to have had the problems since they were 10 years old. Whereas in the other two conditions, uh… they've had the problem, you know, only for the last six months. Those are two potentially very different subsamples. And again, any differences that exists between conditions may impact outcome differentially. Okay. Umm… The next issue is to assess Concurrent and Past Treatments. So, umm… not only psychological treatments, so you not only want to know whether your clients are currently seeing another therapist, but also whether they are on medication, right because those were two potentially very effective interventions. And you… not only concurrently, but in the past. So you just want to ask, "Have you ever seen anybody for any kind of emotional distress or problem?" And again, it's okay if they do, but you want to make sure that it's equivalently distributed across your groups, across your conditions, otherwise you've got a rival hypothesis to explain, umm… any between groups differences that emerge. The other thing, umm… with, uh… concurrent… The other thing with, umm… concurrent pharmacological treatment, medications is, number one, you want to make sure to be collaborative with the prescribing physician, right. Umm… To hold the dosage constant throughout the course of the study, because what's gonna happen if the physician is changing the dosage and the person gets better. Well, was it due to your intervention or was it due to the medication change that the physiatrist implemented. Umm… Also you… It's generally customary to only allow the client into the study, once he or she has been taking the same dosage steadily for at least one month in order to stabilize drug effects, because in the beginning, umm… you know, there're… everybody knows anytime you've ever taken any kind of medications, sometimes there are funky things that happen in the beginning either to your mood or to your physiology or whatever and so you just want to make sure that those are stable before the person enters treatment. And you want to record the dosage and, umm… of all the medications that the perp… that the person is on, in order, again, to ensure equivalence across conditions of the study. And, umm… a lot of people try to exclude participants who are in some sort of, concurrent treatment. And again, this is gonna be a tradeoff, right. So, you get a cleaner sample because there is no outside influence of either another therapist or a medication agent, but you potentially decrease external validity. Umm… You know, and you decrease the generalizability of your findings. Okay. Umm… The next issue is one of diagnosis. So, most psychotherapy outcome studies focus on a particular diagnosis or a particular clinical problem. And, umm… you… you have to have a working definition of what that diagnosis is, right. So the most common is to go with the DSM diagnosis for a particular problem. And to use a semi-structured interview like the SCID, uh… in order to assess the problem, umm… in… in a valid way. And there are some… there are some conditions that have very poor inter-rater reliability. So, for example, specific phobias have great inter-rater reliability. If I have Mary diagnose my client and then I have Joe diagnose the same client. If Mary says this client has specific phobia, Joe is highly likely to agree with that, even though Joe and Mary didn't even discuss the client. But, for generalized anxiety disorder, the reliability is much lower. So Mary might say, yes, this person has GAD, but Joe is only about 40% to 70% likely to agree with her. So, umm… so sometimes when there are, uh… conditions that are being examined in the treatment outcome study, uh… that have poor inter-rater reliability, they will actually go through the trouble of having two impendent interviewers who don't speak to each other and then only include the participants who had an agreed upon diagnosis by these two individuals. Umm… And, you know, you can choose the percentage of clients you're gonna do dual diagnoses on, uh… you know, you can… depending on your resources etcetera, but it is one thing to take into consideration. Again, just for the, umm… the cleanli… the cleanness of the study, right. You just… You want things to be very well defined because it's an experiment. Okay. So that's it for the client and participant characteristics. And now we can segway into talking a little bit about the therapist considerations. So, we talked about, sort of, overall design stuff. Then we talked about, sort of, like session parameters and things like that. Then we talked about, umm… specific client concerns. Who is that you want to bring into the study? How do you define what that is? I mean, I wanted to say one other thing, by the way, about, umm… the diagnoses. So, uh… traditionally psychotherapy outcome research has been performed on people with specific diagnoses. So they would recruit people with depression. Make sure that they met formal diagnostic criteria for depression. If somebody was subthreshold, so like, just under that cutoff for depression, but not quite there, they wouldn't allow them into the study. And over time, that has really fallen out of favor because, A, we know that a lot of psychological conditions are not categorical. It's not like you have it or you don't. And there's this magical thing that happens when you get it. It's more dimensional, right. Like, maybe this person is a little bit less depressed than this person, but the person is clearly still depressed. And so, umm… there is a new initiative, especially if you're the National Institute of Mental Health, to put aside formal diagnoses for a moment and really look at transdiagnostic factors. So issues that transcend diagnoses, umm… things like rumination, right. We see rumination and anxiety, we see it in depression, we see it in so many things or umm… poor emotion regulation skills. And so the focus now is turning more toward trying to treat those issues rather than saying, well, I only want people who meet formal diagnostic criteria for insomnia. Oh, I'm sorry. You've got a goodnight's sleep this… one night this week, you can't be in my study. You know, it's like, if you still struggle with insomnia then you should be in the study, basically. So, that was just the other… the other little thing that I wanted to say. Okay. So aside from those, general concerns, and the client and participant concerns, there are also things that you have to take into consideration when you are selecting therapists for your study. So who should be a study therapist? Well, first of all, you have to pay attention to the individual's level of expertise, right. So you want high… You want these… these therapists to have high quality training, you potentially want them to be licensed, uh… since that comes with its own set of legal liabilities, if the person isn't. Umm… Or you might say, you know what, I'm okay with graduate students being therapists on the study, as long as maybe they are post masters or really, umm… I'm gonna pick, sort of, the grad… the… the graduate students in this program, in this department, who are, who I think are the best clinicians and who have the most training or who received formal training in this specific type of intervention. And you want to collect information on participant's level of experience, number of years practicing, familiarity with the treatment, etcetera. And you want to report all of that in the final paper. So, that again, your reader knows who was treating these people. Umm… And you want to keep in mind, therapists are gonna differ widely on all sorts of individual differences that might impact the treatment process, right. So, there is this whole literature on therapist gender, and therapist warmth, and therapist assertiveness, and all of these different things that go into a therapist personality that may actually impact how well someone does in therapy. There's a whole literature in the counseling, uh… psychology literature on these issues. So… So again, these are all things just to keep in mind and that's why you don't want to just have one therapist, right. Because then it could be that your clients outcome is dependent on these random things in the therapist and not the treatment itself. So you want to have multiple therapists and you want to, umm… and you want to increase generalizability of your findings that way, right. So, this isn't unique to this therapist. This is really about the therapy itself. And look, we employed five therapists, uh… in order to try to flush out some of these effects. When you are assigning therapist to clients, you want to cross therapist with treatment condition. So what you don't want is for your therapist Bob to only be treating people on condition one. And for your therapist Jerry to only be treating people on condition two, right. Because if you find differences between those two conditions, maybe it wasn't the therapy, maybe it was the differences between your two therapists. So you just want to make sure that each therapist is treating an equal number of clients in each condition of the study. And also you want to measure therapist bias. So, some therapist might prefer or believe in one therapy condition over others. And that might be a potential confound in the end, right. Umm… So you want to… In addition to measuring the client's credibility and expectancy, you want to measure the therapist credibility and expectancy. How much do you expect your clients to improve in this therapy condition? And again, you're gonna cross your fingers and hope that your different conditions are equivalent on therapist bias. If they are not, then you have a rival hypothesis to explain any between group's differences that emerge. We can't do anything about it, but at least you can be honest about it in the paper. Okay. And then finally, umm… let's talk a little about the dependent variables. How you're actually gonna measure outcome. So, there are, sort of, three things that you want to take into consideration. Number one, you want to have multiple assessment moments. You want to assess, umm… functioning at multiple times throughout the study. So, you want to do it at pre-therapy. You want to do it at mid-therapy. You want to do it at post-therapy. You want to do it at follow-up, maybe multiple follow-up assessments. And at pre-therapy, you want to make sure that the conditions are equivalent on all outcome measures. So if you're administering The Beck Depression Inventory, and this anxiety measure, and that eating disorders measure, that everybody at pre-therapy across the conditions is equivalent, otherwise, you have a problem, right, because now you have different severity ratings. At mid-therapy, umm… you want to measure outcome at certain predetermined moments. So maybe when you're gonna say, you know what, I'm gonna measure after session three, after session five, after session eight, after session eleven, etcetera, etcetera, and just keep it consistent across people, so that you can look at, umm… changes over the course of therapy. And then at post-therapy, of course, this is what allows you to see the imp… the level of improvement, the degree of improvement across conditions, right, in umm… on your dependent variable. And then the follow-up assessments allow you to examine whether it changed less or whether it's just fleeting and then people go right back to, umm… to their pre-therapy levels. So, in addition to measuring, umm… functioning at different times, you also want to look at different domains of functioning. So, you want to know that… that change is occurring not only in the specific area that you are treating, but maybe in a broader range of areas, right. So, you might want to look at… Let's say that you're doing cognitive therapy. Well, you don't just want to look at cognitive change. You want to look at emotional change. You want to, maybe, look at behavioral change. Maybe, you want to look at physiological change. Lots of people now are doing FMRI studies, before and after therapy, to see whether therapy actually changes the brain in some meaningful way. Maybe you want to look at health outcomes or interpersonal functioning outcomes. You can look at many different areas of peoples' lives because a good therapy should not only target the one thing that you're trying to change. It should really increase the quality of peoples' lives overall. And finally, you want to use multiple forms of assessment. This is, sort of, referred to sometimes as the multi-method approach. So here, you want to not only use self-report questionnaires, but also maybe have people fill out daily dairies or get ratings from independent assessors who are doing formal semi-structured interviews, or maybe do at-home observations. Maybe you're treating children and you want to do a… a home observation on the child behavior checklist just to, you know, look and see whether in the child's actual behavior you see change. Umm… Maybe you want to get third person reports. Maybe you want to get physiological assessments. So, you really want to not only rely on one type of method of assessment, you want to look at many different types of assessment. And when you actually employ assessors, the people who are going to be making these assessments, about your clients, umm… you… again, you want to have them conduct interviews, administer the self-report questionnaires, conduct physiological assessments, conduct observations, etcetera, etcetera, etcetera, and you don't want the assessors to be the same people as the therapists because the therapists will be biased and the therapist will know which condition each client was in. The assessor should be kept blind to condition and just does the assessment as he or she is supposed to do the assessments, so that there's no assessor bias that factors them. And so again, umm… they should be carefully trained. They should be blind to experimental condition. And they should be balanced across conditions of the experiments. So you don't want one assessor assessing everybody from condition one and the other assessor assessing everybody from condition two. So, as you can see there are a ton of considerations that go into conducting a really well controlled, very clean psychotherapy outcome study. This is why these studies take years to run and they are incredibly expensive because you need the personnel to actually, umm… do all of this and make sure that all of these little details are being taken care of. Umm… It's a very, very, very detailed type of research program. Umm… But again, the more you can make sure that all of these things are attended to, the more at the end of the day you're gonna be able to say, hey, it was my treatment. It was the actual manipulation that caused the change in peoples functioning and not anyone of these other, kind of, peripheral things because I made sure that all those other peripheral things were kept constant and consistent across the three conditions. So, thank you so much for umm… your attention and, uh… and I hope that you enjoyed learning all about the different methodological considerations that go into Psychotherapy Outcome Research, aside, above and beyond, just picking a specific type of umm… treatment outcome design. Umm… And thank you. 

00:51:15
Alexander Street 

00:51:15
This program has been made possible as a collaborative effort between Governors State University and the Alexander Street 

00:51:15
Executive Producers: 

00:51:15
Taney Shondel 

00:51:15
Shannon Dermer 

00:51:15
Presenter: 

00:51:15
Evelyn Behar, Ph.D. 

00:51:15
Associate Professor, University of Illinois 

00:51:15
Produced by: 

00:51:15
Governors State University 

00:51:15
Digital Learning and Media Design 

00:51:15
Department Director: 

00:51:15
Charles Nolley 

00:51:15
Video Producer/Director: 

00:51:15
Mark Kundla 

00:51:15
Video Editor: 

00:51:15
Mark Kundla 

00:51:15
Video Engineers: 

00:51:15
Heather Penn 

00:51:15
Arika Rogers 

00:51:15
Audio: 

00:51:15
Jack Mulder 

00:51:15
S. Patrick McCarthy 

00:51:15
Graphic Design: 

00:51:15
Amanda Zaija 

00:51:15
Camera Operators: 

00:51:15
Cherish Brown 

00:51:15
Levilyn Chriss 

00:51:15
Nikki Daily 

00:51:15
Kim Hudson 

00:51:15
Felice Kimbrew 

00:51:15
Jon Tullos 

00:51:15
Alexander Street 

00:51:15
© 2015 

00:51:45
END TRANSCRIPT 